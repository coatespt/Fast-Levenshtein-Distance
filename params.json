{"name":"Fast Estimates of Levenshtein Distance","tagline":"Estimate Levenshtein Distance fast on large files (10's of K to 1000's of K)","body":"### What Is Levenshtein Distance (LD)\r\nLD is a way to express how similar two sequences are. Also called \"edit distance,\" it is the number of single element changes (additions, deletions, etc.) that are needed to turn one sequence into the other. Strings are the most common sequence type we see in programming, but there are many others. In this demo, we'll stick to strings.\r\n\r\n### Why Estimate It? \r\nThe algorithms for LD are quadratic---they take time and space proportional to the length of the two strings (or sequences.) If you're interested in strings of a few hundred characters, fine, use the real LD. But what if you want to look at documents or Web pages that might be 10K up to megabytes? Executing LD on pairs of 20K strings takes several seconds on a fast computer. On 50K strings, a lot of computers can't run it at all because the space required grows at the same rate. Megabytes? Forget it.\r\n\r\n### What Does This Heuristic Do?\r\nThis heuristic compresses the intput radically (25x to 300X might be typical) and then compares the signatures using LD. This time the quadratic space and time complexity work **for** you, because a 100X compression implies a 10,000X speedup. You sacrifice some accuracy, but not too much---estimates are typically within about 0.05 of the true value for related documents, and somewhat worse for random text. \r\n\r\nThe trick is in the compression. A string--say, a paragraph, compressed by itself, looks pretty much like it does when compressed in the middle of a larger document (exactly the same, in fact, except for maybe a few characters at either end.) A pair signatures will tend to differ in locations proportional to where their pre-images differ.  So if you have a document, plus a the same document embedded in an HTML page, the signatures will differ mostly at the beginning, where the header is, and in a few places elsewhere.  The LD of the signatures will be of predictable proportion to the LD of the original files.\r\n\r\nThe signatures can also be used to compare documents that are presumed to be similar to see approximately where they differ. Is one signature more or less contained in another? The same will be true of the corresponding documents. Are differences sprinkled throughout? One document is probably an edited version, or perhaps a text document converted to HTML. Etc.\r\n\r\nOther techniques are discussed in http://hadoopoopadoop.com/2015/11/08/super-fast-estimates-of-levenshtein-distance/\r\n\r\n### Authors and Contributors\r\nThis heuristic is original---some of the incidental code has been cribbed from here or there, and is credited. In particular, the algorithm for computing LD, and the algorithm for computing Shannon Entropy are credited in the code.\r\n\r\n### Support or Contact\r\nPlease feel free to use this idea, and please contact the author if you would like to incorporate your changes here and make this a useful library. ","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}